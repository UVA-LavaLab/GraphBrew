/**
 * @brief Select reordering algorithm using a trained Decision Tree.
 *
 * Auto-generated by scripts/lib/decision_tree.py on 2026-02-24 10:28.
 * Trained on 44 graphs, 7 algorithm classes.
 * Tree depth: 4, leaves: 10.
 * Benchmark: pr.
 *
 * Features used (12):
 *    0. modularity
 *    1. hub_concentration
 *    2. log_nodes
 *    3. log_edges
 *    4. density
 *    5. avg_degree
 *    6. clustering_coefficient
 *    7. packing_factor
 *    8. forward_edge_fraction
 *    9. working_set_ratio
 *   10. community_count
 *   11. diameter
 *
 * @param feat  Graph community features (computed at runtime)
 * @return Algorithm name string
 */
inline std::string SelectAlgorithmDecisionTree_pr(const CommunityFeatures& feat) {
    // Split on modularity
    if (feat.modularity <= 0.617835) {
        // Split on clustering_coefficient
        if (feat.clustering_coeff <= 0.002025) {
            return "HUBSORT"; // 1 training samples
        } else {
            // Split on clustering_coefficient
            if (feat.clustering_coeff <= 0.006265) {
                // Split on density
                if (feat.internal_density <= 0.000200) {
                    return "ORIGINAL"; // 5 training samples
                } else {
                    return "RCM"; // 1 training samples
                }
            } else {
                // Split on packing_factor
                if (feat.packing_factor <= 0.019490) {
                    return "SORT"; // 13 training samples
                } else {
                    return "ORIGINAL"; // 1 training samples
                }
            }
        }
    } else {
        // Split on density
        if (feat.internal_density <= 0.000575) {
            // Split on log_edges
            if (std::log10(static_cast<double>(feat.num_edges) + 1.0) <= 6.489843) {
                // Split on packing_factor
                if (feat.packing_factor <= 0.014500) {
                    return "RABBIT"; // 5 training samples
                } else {
                    return "LEIDEN"; // 3 training samples
                }
            } else {
                // Split on log_nodes
                if (std::log10(static_cast<double>(feat.num_nodes) + 1.0) <= 5.666303) {
                    return "RCM"; // 6 training samples
                } else {
                    return "LEIDEN"; // 8 training samples
                }
            }
        } else {
            return "HUBSORT"; // 1 training samples
        }
    }
}

/**
 * @brief Select reordering algorithm using a trained Decision Tree.
 *
 * Auto-generated by scripts/lib/decision_tree.py on 2026-02-24 10:28.
 * Trained on 44 graphs, 6 algorithm classes.
 * Tree depth: 4, leaves: 7.
 * Benchmark: bfs.
 *
 * Features used (12):
 *    0. modularity
 *    1. hub_concentration
 *    2. log_nodes
 *    3. log_edges
 *    4. density
 *    5. avg_degree
 *    6. clustering_coefficient
 *    7. packing_factor
 *    8. forward_edge_fraction
 *    9. working_set_ratio
 *   10. community_count
 *   11. diameter
 *
 * @param feat  Graph community features (computed at runtime)
 * @return Algorithm name string
 */
inline std::string SelectAlgorithmDecisionTree_bfs(const CommunityFeatures& feat) {
    // Split on avg_degree
    if (feat.avg_degree / 100.0 <= 0.201555) {
        // Split on forward_edge_fraction
        if (feat.forward_edge_fraction <= 0.495145) {
            // Split on density
            if (feat.internal_density <= 0.000025) {
                return "HUBSORT"; // 6 training samples
            } else {
                return "HUBSORT"; // 5 training samples
            }
        } else {
            // Split on clustering_coefficient
            if (feat.clustering_coeff <= 0.039210) {
                // Split on packing_factor
                if (feat.packing_factor <= 0.012195) {
                    return "RCM"; // 5 training samples
                } else {
                    return "RCM"; // 5 training samples
                }
            } else {
                // Split on modularity
                if (feat.modularity <= 0.709265) {
                    return "RABBIT"; // 13 training samples
                } else {
                    return "GORDER"; // 5 training samples
                }
            }
        }
    } else {
        return "SORT"; // 5 training samples
    }
}

/**
 * @brief Select reordering algorithm using a trained Decision Tree.
 *
 * Auto-generated by scripts/lib/decision_tree.py on 2026-02-24 10:28.
 * Trained on 44 graphs, 5 algorithm classes.
 * Tree depth: 3, leaves: 7.
 * Benchmark: cc.
 *
 * Features used (12):
 *    0. modularity
 *    1. hub_concentration
 *    2. log_nodes
 *    3. log_edges
 *    4. density
 *    5. avg_degree
 *    6. clustering_coefficient
 *    7. packing_factor
 *    8. forward_edge_fraction
 *    9. working_set_ratio
 *   10. community_count
 *   11. diameter
 *
 * @param feat  Graph community features (computed at runtime)
 * @return Algorithm name string
 */
inline std::string SelectAlgorithmDecisionTree_cc(const CommunityFeatures& feat) {
    // Split on density
    if (feat.internal_density <= 0.000135) {
        // Split on clustering_coefficient
        if (feat.clustering_coeff <= 0.023985) {
            // Split on avg_degree
            if (feat.avg_degree / 100.0 <= 0.073335) {
                return "GORDER"; // 4 training samples
            } else {
                return "HUBSORT"; // 4 training samples
            }
        } else {
            // Split on diameter
            if (feat.diameter_estimate / 50.0 <= 0.190000) {
                return "LEIDEN"; // 10 training samples
            } else {
                return "RABBIT"; // 11 training samples
            }
        }
    } else {
        // Split on hub_concentration
        if (feat.hub_concentration <= 0.402295) {
            return "GORDER"; // 5 training samples
        } else {
            // Split on forward_edge_fraction
            if (feat.forward_edge_fraction <= 0.502605) {
                return "SORT"; // 5 training samples
            } else {
                return "SORT"; // 5 training samples
            }
        }
    }
}

/**
 * @brief Select reordering algorithm using a trained Decision Tree.
 *
 * Auto-generated by scripts/lib/decision_tree.py on 2026-02-24 10:28.
 * Trained on 44 graphs, 4 algorithm classes.
 * Tree depth: 9, leaves: 15.
 * Benchmark: sssp.
 *
 * Features used (12):
 *    0. modularity
 *    1. hub_concentration
 *    2. log_nodes
 *    3. log_edges
 *    4. density
 *    5. avg_degree
 *    6. clustering_coefficient
 *    7. packing_factor
 *    8. forward_edge_fraction
 *    9. working_set_ratio
 *   10. community_count
 *   11. diameter
 *
 * @param feat  Graph community features (computed at runtime)
 * @return Algorithm name string
 */
inline std::string SelectAlgorithmDecisionTree_sssp(const CommunityFeatures& feat) {
    // Split on working_set_ratio
    if (std::log2(feat.working_set_ratio + 1.0) <= 0.047741) {
        // Split on log_edges
        if (std::log10(static_cast<double>(feat.num_edges) + 1.0) <= 4.692991) {
            return "LEIDEN"; // 2 training samples
        } else {
            return "RABBIT"; // 5 training samples
        }
    } else {
        // Split on log_edges
        if (std::log10(static_cast<double>(feat.num_edges) + 1.0) <= 5.518213) {
            return "GORDER"; // 3 training samples
        } else {
            // Split on avg_degree
            if (feat.avg_degree / 100.0 <= 0.063794) {
                // Split on log_nodes
                if (std::log10(static_cast<double>(feat.num_nodes) + 1.0) <= 6.219410) {
                    return "LEIDEN"; // 7 training samples
                } else {
                    return "RABBIT"; // 2 training samples
                }
            } else {
                // Split on avg_degree
                if (feat.avg_degree / 100.0 <= 0.248853) {
                    // Split on modularity
                    if (feat.modularity <= 0.819005) {
                        // Split on diameter
                        if (feat.diameter_estimate / 50.0 <= 0.150000) {
                            // Split on log_edges
                            if (std::log10(static_cast<double>(feat.num_edges) + 1.0) <= 6.296836) {
                                return "RCM"; // 5 training samples
                            } else {
                                // Split on clustering_coefficient
                                if (feat.clustering_coeff <= 0.272790) {
                                    // Split on packing_factor
                                    if (feat.packing_factor <= 0.019515) {
                                        return "GORDER"; // 4 training samples
                                    } else {
                                        return "RCM"; // 1 training samples
                                    }
                                } else {
                                    return "RCM"; // 2 training samples
                                }
                            }
                        } else {
                            // Split on forward_edge_fraction
                            if (feat.forward_edge_fraction <= 0.502465) {
                                // Split on avg_degree
                                if (feat.avg_degree / 100.0 <= 0.108048) {
                                    return "RABBIT"; // 2 training samples
                                } else {
                                    // Split on density
                                    if (feat.internal_density <= 0.000050) {
                                        return "RCM"; // 1 training samples
                                    } else {
                                        return "LEIDEN"; // 3 training samples
                                    }
                                }
                            } else {
                                return "GORDER"; // 2 training samples
                            }
                        }
                    } else {
                        return "LEIDEN"; // 3 training samples
                    }
                } else {
                    return "RABBIT"; // 2 training samples
                }
            }
        }
    }
}

/**
 * @brief Select reordering algorithm using a trained Decision Tree.
 *
 * Auto-generated by scripts/lib/decision_tree.py on 2026-02-24 10:28.
 * Trained on 44 graphs, 4 algorithm classes.
 * Tree depth: 6, leaves: 12.
 * Benchmark: bc.
 *
 * Features used (12):
 *    0. modularity
 *    1. hub_concentration
 *    2. log_nodes
 *    3. log_edges
 *    4. density
 *    5. avg_degree
 *    6. clustering_coefficient
 *    7. packing_factor
 *    8. forward_edge_fraction
 *    9. working_set_ratio
 *   10. community_count
 *   11. diameter
 *
 * @param feat  Graph community features (computed at runtime)
 * @return Algorithm name string
 */
inline std::string SelectAlgorithmDecisionTree_bc(const CommunityFeatures& feat) {
    // Split on clustering_coefficient
    if (feat.clustering_coeff <= 0.005345) {
        return "RCM"; // 5 training samples
    } else {
        // Split on forward_edge_fraction
        if (feat.forward_edge_fraction <= 0.506860) {
            // Split on working_set_ratio
            if (std::log2(feat.working_set_ratio + 1.0) <= 0.051389) {
                return "RABBIT"; // 5 training samples
            } else {
                // Split on clustering_coefficient
                if (feat.clustering_coeff <= 0.062330) {
                    // Split on hub_concentration
                    if (feat.hub_concentration <= 0.718720) {
                        // Split on clustering_coefficient
                        if (feat.clustering_coeff <= 0.006195) {
                            return "GORDER"; // 1 training samples
                        } else {
                            return "RABBIT"; // 5 training samples
                        }
                    } else {
                        return "RCM"; // 2 training samples
                    }
                } else {
                    // Split on forward_edge_fraction
                    if (feat.forward_edge_fraction <= 0.498940) {
                        // Split on modularity
                        if (feat.modularity <= 0.630025) {
                            return "GORDER"; // 4 training samples
                        } else {
                            return "GORDER"; // 6 training samples
                        }
                    } else {
                        // Split on packing_factor
                        if (feat.packing_factor <= 0.016770) {
                            return "LEIDEN"; // 6 training samples
                        } else {
                            return "RCM"; // 3 training samples
                        }
                    }
                }
            }
        } else {
            // Split on clustering_coefficient
            if (feat.clustering_coeff <= 0.061480) {
                // Split on log_nodes
                if (std::log10(static_cast<double>(feat.num_nodes) + 1.0) <= 5.095817) {
                    return "LEIDEN"; // 1 training samples
                } else {
                    return "LEIDEN"; // 4 training samples
                }
            } else {
                return "RCM"; // 2 training samples
            }
        }
    }
}

/**
 * @brief Select algorithm using the benchmark-specific Decision Tree.
 *
 * Dispatches to the appropriate per-benchmark tree based on the
 * benchmark being run. Falls back to the generic tree if available.
 */
inline std::string SelectAlgorithmDecisionTreeDispatch(
    const CommunityFeatures& feat,
    const std::string& benchmark)
{
    if (benchmark == "pr") {
        return SelectAlgorithmDecisionTree_pr(feat);
    } else if (benchmark == "bfs") {
        return SelectAlgorithmDecisionTree_bfs(feat);
    } else if (benchmark == "cc") {
        return SelectAlgorithmDecisionTree_cc(feat);
    } else if (benchmark == "sssp") {
        return SelectAlgorithmDecisionTree_sssp(feat);
    } else if (benchmark == "bc") {
        return SelectAlgorithmDecisionTree_bc(feat);
    } else {
        return SelectAlgorithmDecisionTree_pr(feat);
    }
}
