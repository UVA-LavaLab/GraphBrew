# AdaptiveOrder-ML — Repo Map

> Generated by agent from code (not docs). Every claim verified against source.

---

## 1  Entry Points

| Layer | File | Line(s) | What happens |
|-------|------|---------|--------------|
| CLI | `bench/src/pr.cc` (and all `bench/src/*.cc`) | CLI `-o 14[:opts]` | Parsed by `CLBase` → `reordering_algo = 14`, tokens stored in `reordering_options` |
| Dispatch | `bench/include/external/gapbs/builder.h` | L1246–1248 | `case AdaptiveOrder: GenerateAdaptiveMapping(...)` |
| Delegate | `bench/include/external/gapbs/builder.h` | L2798–2801 | Thin wrapper → `::GenerateAdaptiveMappingStandalone(g, new_ids, useOutdeg, opts)` |
| Implementation | `bench/include/graphbrew/reorder/reorder_adaptive.h` | L558–609 | Main entry: parses mode token, dispatches to Full-Graph or Recursive |
| Python experiment | `scripts/graphbrew_experiment.py` | `--phase reorder` | Calls binary with `-o 14:...` args, collects `.lo` label maps |
| Python training | `scripts/lib/training.py` | L179 | `train_adaptive_weights_iterative()` — brute-force + perceptron update loop |

---

## 2  Core Modules — Dependency Graph

```
CLI (-o 14:max_depth:resolution:min_size:mode)
 │
 ▼
builder.h  case AdaptiveOrder
 │
 ▼
reorder_adaptive.h::GenerateAdaptiveMappingStandalone()
 ├── Parses selection_mode (0–3, or 100 for legacy full-graph)
 ├── If mode==100 → GenerateAdaptiveMappingFullGraphStandalone()
 │     ├── ComputeSampledDegreeFeatures(g, 10000)
 │     ├── DetectGraphType(mod, dv, hub, deg, N)
 │     ├── SelectBestReorderingForCommunity(...)
 │     └── ApplyBasicReorderingStandalone(g, new_ids, algo)
 │
 └── Default → GenerateAdaptiveMappingRecursiveStandalone()
       │
       ├─ 1. GVE-Leiden (native CSR)
       │     graphbrew::runGraphBrew<K>(g, gb_config)
       │     → membership[], modularity
       │     (reorder_graphbrew.h, LeidenAutoResolution)
       │
       ├─ 2. Feature Extraction
       │     ComputeSampledDegreeFeatures(g, 10000, true)
       │       → degree_variance, hub_concentration,
       │         clustering_coeff, packing_factor,
       │         forward_edge_fraction, working_set_ratio
       │     DetectGraphType(mod, dv, hub, deg, N)
       │
       ├─ 3. Dynamic Thresholds
       │     ComputeDynamicMinCommunitySize(N, #comm, avg)
       │     ComputeDynamicLocalReorderThreshold(N, #comm, avg)
       │
       ├─ 4. Small Communities (< MIN_LOCAL_REORDER)
       │     ComputeMergedCommunityFeatures(g, nodes, set)
       │     SelectAlgorithmForSmallGroup(merged_feat)
       │     ReorderCommunitySubgraphStandalone(g, nodes, algo)
       │
       └─ 5. Large Communities (≥ MIN_LOCAL_REORDER)
             FOR each community:
             ├── ComputeCommunityFeaturesStandalone(nodes, g, set)
             ├── SelectBestReorderingForCommunity(feat, ...)
             │     ├── Size guard: < MIN_COMMUNITY_SIZE → ORIGINAL
             │     └── SelectReorderingWithMode(feat, ...)
             │           ├── FindBestTypeWithDistance(mod, dv, hub, ...)
             │           │     → type_name, type_distance
             │           ├── OOD guardrail: distance > 1.5 → ORIGINAL
             │           ├── MODE_FASTEST_REORDER(0):
             │           │     SelectFastestReorderFromWeights(weights)
             │           ├── MODE_FASTEST_EXECUTION(1) [default]:
             │           │     SelectReorderingPerceptronWithFeatures(feat, ...)
             │           │       LoadPerceptronWeightsForFeatures(feat, ...)
             │           │         → type_0..10.json → {algo: PerceptronWeights}
             │           │       SelectReorderingFromWeights(feat, weights)
             │           │         → per-algo score(), pick argmax
             │           │         → ORIGINAL margin check (< 0.05 → ORIGINAL)
             │           ├── MODE_BEST_ENDTOEND(2):
             │           │     Perceptron + 2× reorder_time boost
             │           └── MODE_BEST_AMORTIZATION(3):
             │                 iterationsToAmortize() → pick lowest
             └── ReorderCommunitySubgraphStandalone(g, nodes, algo, ...)
                   → subgraph extraction + dispatch to Sort/DBG/HubSort/etc.
                   → writes contiguous IDs into new_ids[current_id..]
```

---

## 3  File → Responsibility Map

### C++ Headers

| File | Lines | Responsibility |
|------|:-----:|----------------|
| `bench/include/graphbrew/reorder/reorder_types.h` | 4622 | **Core ML engine**: `PerceptronWeights`, `CommunityFeatures`, `SampledDegreeFeatures`, `score()`/`scoreBase()`, `SelectReorderingFromWeights()`, `SelectReorderingWithMode()`, `SelectBestReorderingForCommunity()`, `FindBestTypeWithDistance()`, `LoadPerceptronWeightsForFeatures()`, `ComputeSampledDegreeFeatures()`, `ComputeCommunityFeaturesStandalone()`, type registry parsing, weight file I/O, JSON parsing, graph-type detection, OOD guardrail, ORIGINAL margin |
| `bench/include/graphbrew/reorder/reorder_adaptive.h` | 653 | **AdaptiveOrder dispatcher**: `AdaptiveConfig`, `GenerateAdaptiveMappingStandalone()`, `GenerateAdaptiveMappingFullGraphStandalone()`, `GenerateAdaptiveMappingRecursiveStandalone()`, `SelectHeuristicFallback()`, `ShouldRecurse()`, options parsing |
| `bench/include/graphbrew/reorder/reorder_graphbrew.h` | ~7100 | GVE-Leiden engine (`runGraphBrew`), community-sort mapping, `LeidenAutoResolution()`, GraphBrew variants |
| `bench/include/external/gapbs/builder.h` | 3648 | Graph builder, reorder dispatch (case 14), CLI parsing, `GenerateAdaptiveMapping()` delegator |
| `bench/include/external/gapbs/util.h` | — | `ReorderingAlgo` enum: `AdaptiveOrder = 14` |

### Python Scripts

| File | Lines | Responsibility |
|------|:-----:|----------------|
| `scripts/graphbrew_experiment.py` | — | **Single experiment tool**: download→convert→reorder→benchmark→weights pipeline |
| `scripts/lib/training.py` | 721 | `train_adaptive_weights_iterative()`, `train_adaptive_weights_large_scale()` — brute-force eval + weight update loop |
| `scripts/lib/weights.py` | 2221 | `PerceptronWeight` dataclass, `_normalize_features()`, `_compute_distance()`, type registry CRUD, `assign_graph_type()`, `update_type_weights_incremental()`, `get_best_algorithm_for_type()` |
| `scripts/lib/features.py` | — | Graph feature computation (Python side) |
| `scripts/lib/metrics.py` | — | Amortization, E2E speedup, variant comparison |
| `scripts/lib/utils.py` | — | `ALGORITHMS`, `GRAPHBREW_VARIANTS`, `GRAPHBREW_OPTIONS` constants |
| `scripts/lib/download.py` | — | Graph catalog: `DOWNLOAD_GRAPHS_SMALL/MEDIUM/LARGE/XLARGE` |

### Weight Files (runtime data)

| Path | Purpose |
|------|---------|
| `results/weights/registry.json` | 11 type centroids (7D normalized features each) — k-means auto-generated |
| `results/weights/type_0/weights.json` – `type_10/weights.json` | Per-type perceptron weights: `{algo_id: {bias, w_modularity, w_log_nodes, ...}}` |
| `results/weights/graph_properties_cache.json` | Cached per-graph features (avoid recomputation) |

---

## 4  Call Chain: CLI → Output Mapping

```
pr -g graph.sg -o 14:0:0.8:50000:1
                  │  │  │    │    └─ selection_mode=1 (MODE_FASTEST_EXECUTION)
                  │  │  │    └───── min_recurse_size=50000
                  │  │  └────────── resolution=0.8
                  │  └───────────── max_depth=0
                  └──────────────── algo=14 (AdaptiveOrder)

1. builder.h::MakeGraph()
   └── GenerateMapping(g, new_ids, 14, opts)
       └── case AdaptiveOrder → GenerateAdaptiveMapping()
           └── ::GenerateAdaptiveMappingStandalone()

2. reorder_adaptive.h  (line 558)
   Parse mode from opts[3] → MODE_FASTEST_EXECUTION
   └── GenerateAdaptiveMappingRecursiveStandalone()

3. Leiden partitioning  (line 432, calls reorder_graphbrew.h)
   graphbrew::runGraphBrew<K>(g, {resolution=0.8, maxIter=30, maxPass=30})
   → community membership[], modularity

4. Feature extraction  (line 465)
   ComputeSampledDegreeFeatures(g, 10000, true)
   → {degree_var, hub_conc, clustering, packing, fef, wsr}
   DetectGraphType(mod, dv, hub, deg, N) → enum GraphType

5. Community loop  (line 523)
   FOR each large community:
     ComputeCommunityFeaturesStandalone(nodes, g, set)
     SelectBestReorderingForCommunity(feat, global_*, BENCH_GENERIC, type)
       └── SelectReorderingWithMode(feat, ..., MODE_FASTEST_EXECUTION)
             ├── FindBestTypeWithDistance(...) → type_name, dist
             ├── OOD check: dist > 1.5 → ORIGINAL (safety bail)
             └── SelectReorderingPerceptronWithFeatures(feat, ...)
                   ├── LoadPerceptronWeightsForFeatures(mod, dv, hub, ...)
                   │     → reads type_X.json from disk
                   └── SelectReorderingFromWeights(feat, weights)
                         ├── for each algo: score = w.score(feat, bench)
                         ├── argmax → best_algo
                         └── margin < 0.05 → ORIGINAL
     ReorderCommunitySubgraphStandalone(g, nodes, selected_algo, outdeg, new_ids, cur_id)
       → contiguous IDs assigned to new_ids[node] = current_id++

6. Output: pvector<NodeID_> new_ids — permutation [0, N)
   Applied by builder.h to relabel the CSR graph.
```

---

## 5  Safety / Fallback Summary

| Guard | Location | Condition | Action |
|-------|----------|-----------|--------|
| Empty graph | `reorder_adaptive.h:330` | `num_nodes == 0` | Identity mapping, return |
| Small community | `reorder_types.h:3930` | `feat.num_nodes < MIN_COMMUNITY_SIZE` | Return `ORIGINAL` |
| OOD guardrail | `reorder_types.h:3717` | `type_distance > 1.5` | Return `ORIGINAL` (except `MODE_FASTEST_REORDER`) |
| ORIGINAL margin | `reorder_types.h:3608` | `best_score - original_score < 0.05` | Return `ORIGINAL` |
| RabbitOrder check | `reorder_types.h:3951` | `selected == RabbitOrder && !RABBIT_ENABLE` | Heuristic fallback |
| Heuristic fallback | `reorder_adaptive.h:175` | No weights / legacy path | `SelectHeuristicFallback()` rules |

---

## 6  Feature Vector (18 dimensions)

### 15 Linear Features (scored in `scoreBase()`)

| # | Feature | Weight field | Normalization in C++ |
|---|---------|-------------|---------------------|
| 1 | Modularity | `w_modularity` | raw |
| 2 | log₁₀(nodes+1) | `w_log_nodes` | raw |
| 3 | log₁₀(edges+1) | `w_log_edges` | raw |
| 4 | Internal density | `w_density` | raw |
| 5 | avg_degree / 100 | `w_avg_degree` | ÷ 100 |
| 6 | Degree variance (CV) | `w_degree_variance` | raw |
| 7 | Hub concentration | `w_hub_concentration` | raw |
| 8 | Clustering coeff | `w_clustering_coeff` | raw |
| 9 | avg_path_length / 10 | `w_avg_path_length` | ÷ 10 |
| 10 | diameter / 50 | `w_diameter` | ÷ 50 |
| 11 | log₁₀(community_count+1) | `w_community_count` | log10 |
| 12 | Packing factor (IISWC'18) | `w_packing_factor` | raw |
| 13 | Forward edge fraction (GoGraph) | `w_forward_edge_fraction` | raw |
| 14 | log₂(working_set_ratio+1) (P-OPT) | `w_working_set_ratio` | log2 |
| 15 | Reorder time | `w_reorder_time` | raw |

### 3 Quadratic Cross-terms

| # | Interaction | Weight field |
|---|-------------|-------------|
| 16 | degree_var × hub_conc | `w_dv_x_hub` |
| 17 | modularity × log₁₀(N+1) | `w_mod_x_logn` |
| 18 | packing × log₂(wsr+1) | `w_pf_x_wsr` |

### 1 Conditional Bonus

| # | Feature | When applied |
|---|---------|-------------|
| 19 | `w_fef_convergence` × forward_edge_fraction | `bench ∈ {PR, SSSP}` only |

### 4 Cache Weights (constant per algo, not feature-dependent)

`cache_l1 × 0.5 + cache_l2 × 0.3 + cache_l3 × 0.2 + cache_dram_penalty`

### Benchmark Multipliers

6 per-benchmark multipliers: `{pr, bfs, cc, sssp, bc, tc}` — scale final score.

---

## 7  Type System

- **11 types** (type_0 – type_10) auto-generated by k-means clustering
- 7D centroid vector: `[modularity, degree_var/5, hub_conc, avg_deg/100, clustering, (log₁₀(N+1)-3)/7, (log₁₀(E+1)-3)/9]` — all normalized to [0,1]
- Matching: Euclidean distance in 7D space, pick closest centroid
- Unknown threshold: distance > 1.5 → OOD flag
- Each type has its own `type_X.json` with per-algorithm weights
- Python `_normalize_features()` in `scripts/lib/weights.py:184` — **verified identical** to C++ normalization in `reorder_types.h:3232`

---

## 8  Training Pipeline

```
graphbrew_experiment.py --phase weights --train
 │
 └── training.py::train_adaptive_weights_iterative()
       │
       ├── FOR each iteration (max 10):
       │   ├── Brute-force: run ALL algorithms on ALL graphs → measure speedups
       │   ├── Adaptive prediction: run adaptive selection → measure accuracy
       │   ├── Identify mismatches (predicted ≠ oracle best)
       │   ├── weights.py::assign_graph_type(features) → type_name
       │   ├── weights.py::update_type_weights_incremental(type, corrections, lr)
       │   └── Save updated type_X.json files
       │
       └── Result: type_registry.json + type_X.json files in weights/active/
```

---

## 9  Normalization Parity Check (Python ↔ C++)

| Feature | Python range | C++ range | Match? |
|---------|-------------|-----------|:------:|
| modularity | [0, 1] | [0, 1] | ✅ |
| degree_variance | [0, 5] | [0, 5] (÷5) | ✅ |
| hub_concentration | [0, 1] | [0, 1] | ✅ |
| avg_degree | [0, 100] | [0, 100] (÷100) | ✅ |
| clustering_coeff | [0, 1] | [0, 1] | ✅ |
| log_nodes | [3, 10] | [3, 10] (−3)/7 | ✅ |
| log_edges | [3, 12] | [3, 12] (−3)/9 | ✅ |

Note: The normalization ranges above are for **type matching** (distance computation). The **perceptron scoring** uses different per-feature normalization (e.g., avg_degree÷100, diameter÷50) applied inline in `scoreBase()`.
